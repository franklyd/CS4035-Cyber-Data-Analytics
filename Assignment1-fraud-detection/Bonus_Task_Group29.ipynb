{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task Data aggregation\n",
    "1. Check whether it is a foreign transaction: \n",
    "\n",
    "2. Aggregated several features:\n",
    "    * Previous daily average amount\n",
    "    * Previous number of transactions per day\n",
    "    * Number of transactions today before current one\n",
    "    * Total amount today before current transaction\n",
    "    * Number of previous transactions which were using the same currency as this transaction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiang\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please notice that:\n",
    "Because it takes a long time to get these features, I just saved them in a'csv' file, and you don't need to run the coede below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check whether it is a foreign transaction\n",
    "cleaned_df['foreign_transaction'] = cleaned_df.apply(lambda x: x['issuercountrycode']!=x['shoppercountrycode'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the Dataframe \n",
    "cleaned_df = cleaned_df.sort_values('creation_date')\n",
    "\n",
    "pre_avg = []\n",
    "prev_daily_num = []\n",
    "tdy_num = []\n",
    "tdy_sum = []\n",
    "cry_prev_count = []\n",
    "\n",
    "for i in range(len(cleaned_df)):\n",
    "    row = cleaned_df.iloc[i]\n",
    "    # All previous transactions\n",
    "    previous_data = cleaned_df[0:i]\n",
    "    # Match current card id\n",
    "    previous_data = previous_data[previous_data.card_id==row.card_id]\n",
    "    previous_average_daily = np.mean(previous_data['amount'].groupby(previous_data.creation_day).mean())\n",
    "    \n",
    "    if len(previous_data) == 0:\n",
    "        previous_average = 0\n",
    "        previous_daily_num = 0\n",
    "        currency_previous_count = 0\n",
    "    else:\n",
    "        previous_average = np.mean(previous_data.amount)\n",
    "        previous_daily_num =  np.mean(previous_data['amount'].groupby(previous_data.creation_day).count())\n",
    "        currency_previous_count = sum(previous_data.currencycode==row.currencycode)\n",
    "    # Match today's transaction\n",
    "    today_transaction = previous_data[previous_data.creation_day==row.creation_day]\n",
    "    if len(today_transaction)==0:\n",
    "        today_num = 0\n",
    "        today_sum = 0\n",
    "        \n",
    "    else:\n",
    "        today_num = len(today_transaction)\n",
    "        today_sum = sum(today_transaction.amount)\n",
    "    \n",
    "    # Append the result in list accordingly\n",
    "    pre_avg.append(previous_average)\n",
    "    prev_daily_num.append(previous_daily_num)\n",
    "    tdy_num.append(today_num)\n",
    "    tdy_sum.append(today_sum)\n",
    "    cry_prev_count.append(currency_previous_count)\n",
    "    \n",
    "    if i%2000 == 0 :\n",
    "        print 'finished %d' %i\n",
    "\n",
    "# Add these colunms as new features\n",
    "cleaned_df['previous_average'] = pre_avg\n",
    "cleaned_df['previous_daily_num'] = prev_daily_num\n",
    "cleaned_df['today_num'] = tdy_num\n",
    "cleaned_df['today_sum'] = tdy_sum\n",
    "cleaned_df['currency_prev_count'] = cry_prev_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You start here!\n",
    "Here we load in 'aggregated data', which is a pre-saved file.\n",
    "You can downloade the file here: https://drive.google.com/file/d/0B5YbrNDkPK3nTEFMZkJiQXdFRUU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_df = pd.read_csv('aggregated_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, transform numerical variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "cleaned_df['previous_average'] = StandardScaler().fit_transform(cleaned_df['previous_average'].values.reshape(-1, 1))\n",
    "cleaned_df['today_sum'] = StandardScaler().fit_transform(cleaned_df['today_sum'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the features we don't need\n",
    "data_aggregated = cleaned_df.drop(['Unnamed: 0','txid','bookingdate','amount','simple_journal','converted_amount','creation_date','creationdate','card_id','ip_id','mail_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_encoding(data,column,threshold):\n",
    "    count = dict(data[column].value_counts())\n",
    "    mapping = {}\n",
    "    for id in count.keys():\n",
    "        if count[id]>threshold:\n",
    "            mapping[id] = id\n",
    "        else:\n",
    "            mapping[id] = 'others'\n",
    "    data[column] = data[column].map(mapping)\n",
    "    return data\n",
    "\n",
    "data_aggregated = dense_encoding(data_aggregated,'bin',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode for ordinal feature: creation day\n",
    "date_mapping = {label:idx for idx,label in enumerate(data_aggregated['creation_day'].unique())}\n",
    "data_aggregated['creation_day'] = data_aggregated['creation_day'].map(date_mapping)\n",
    "# Encode for categorical variables\n",
    "columns = list(data_aggregated.columns)\n",
    "columns.remove('norm_amount')\n",
    "columns.remove('norm_converted_amount')\n",
    "columns.remove('label')\n",
    "columns.remove('creation_day')\n",
    "columns.remove('creation_month')\n",
    "columns.remove('currency_prev_count')\n",
    "columns.remove('today_sum')\n",
    "columns.remove('today_num')\n",
    "columns.remove('previous_daily_num')\n",
    "columns.remove('previous_average')\n",
    "columns.remove('foreign_transaction')\n",
    "\n",
    "# OneHot Encoding\n",
    "encoded_data = pd.get_dummies(data_aggregated,columns=columns,dummy_na=True)\n",
    "\n",
    "## Training data X and label y\n",
    "X = encoded_data.ix[:,encoded_data.columns !='label']\n",
    "y = encoded_data.ix[:,encoded_data.columns =='label'].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build two models: ramdon forest and logistic regression\n",
    "1. Build two models\n",
    "2. Using 10-folds cross validation to evaluate our results\n",
    "3. Compare with the previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utilities import ten_fold_CV_eval\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "forest = RandomForestClassifier(n_estimators=250, n_jobs=4)\n",
    "lr = LogisticRegression(C=400, penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0 fold:\n",
      "Finished SMOTE!\n",
      "23661 9 32 3\n",
      "Start 1 fold:\n",
      "Finished SMOTE!\n",
      "23661 8 34 1\n",
      "Start 2 fold:\n",
      "Finished SMOTE!\n",
      "23661 8 28 7\n",
      "Start 3 fold:\n",
      "Finished SMOTE!\n",
      "23663 6 30 5\n",
      "Start 4 fold:\n",
      "Finished SMOTE!\n",
      "23663 6 29 6\n",
      "Start 5 fold:\n",
      "Finished SMOTE!\n",
      "23662 7 29 5\n",
      "Start 6 fold:\n",
      "Finished SMOTE!\n",
      "23662 7 32 2\n",
      "Start 7 fold:\n",
      "Finished SMOTE!\n",
      "23664 5 32 2\n",
      "Start 8 fold:\n",
      "Finished SMOTE!\n",
      "23661 8 31 3\n",
      "Start 9 fold:\n",
      "Finished SMOTE!\n",
      "23665 4 31 3\n"
     ]
    }
   ],
   "source": [
    "avg_score, avg_acc, avg_precsion, avg_recall, avg_f1,avg_fhalf = ten_fold_CV_eval(forest,X,y, r= 0.01,t = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average auc score of aggregated model is:0.878,    average auc score of non-aggregated model is:0.890\n",
      "average accuracy of aggregated model is:0.998,     average accuracy of non-aggregated model is0.999\n",
      "average precision of aggregated model is:0.341,    average precision of non-aggregated model is:0.434\n",
      "average recall of aggregated model is:0.107,       average recall of non-aggregated model is:0.107\n",
      "average F1 score of aggregated model is:0.161,     average F1 score of non-aggregated modelis:0.168\n",
      "average F0.5 score of aggregated model is:0.234,   average F0.5 score of non-aggregated model is:0.261\n"
     ]
    }
   ],
   "source": [
    "#print the results of aggregated model and non-aggregated model respectively for Random Forest. \n",
    "print (\"average auc score of aggregated model is:%0.3f,    average auc score of non-aggregated model is:%0.3f\" % (avg_score,0.890))\n",
    "print (\"average accuracy of aggregated model is:%0.3f,     average accuracy of non-aggregated model is%0.3f\" % (avg_acc,0.999))\n",
    "print (\"average precision of aggregated model is:%0.3f,    average precision of non-aggregated model is:%0.3f\" % (avg_precsion,0.434))\n",
    "print (\"average recall of aggregated model is:%0.3f,       average recall of non-aggregated model is:%0.3f\" % (avg_recall,0.107))\n",
    "print (\"average F1 score of aggregated model is:%0.3f,     average F1 score of non-aggregated modelis:%0.3f\" % (avg_f1,0.168))\n",
    "print (\"average F0.5 score of aggregated model is:%0.3f,   average F0.5 score of non-aggregated model is:%0.3f\" % (avg_fhalf,0.261))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 0 fold:\n",
      "Finished SMOTE!\n",
      "23647 23 27 8\n",
      "Start 1 fold:\n",
      "Finished SMOTE!\n",
      "23641 28 30 5\n",
      "Start 2 fold:\n",
      "Finished SMOTE!\n",
      "23635 34 29 6\n",
      "Start 3 fold:\n",
      "Finished SMOTE!\n",
      "23627 42 31 4\n",
      "Start 4 fold:\n",
      "Finished SMOTE!\n",
      "23632 37 29 6\n",
      "Start 5 fold:\n",
      "Finished SMOTE!\n",
      "23637 32 28 6\n",
      "Start 6 fold:\n",
      "Finished SMOTE!\n",
      "23642 27 30 4\n",
      "Start 7 fold:\n",
      "Finished SMOTE!\n",
      "23640 29 27 7\n",
      "Start 8 fold:\n",
      "Finished SMOTE!\n",
      "23644 25 27 7\n",
      "Start 9 fold:\n",
      "Finished SMOTE!\n",
      "23638 31 28 6\n"
     ]
    }
   ],
   "source": [
    "avg_score1, avg_acc1, avg_precsion1, avg_recall1, avg_f11,avg_fhalf1 = ten_fold_CV_eval(lr,X,y, r = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91471219365233092,\n",
       " 0.99749405217538778,\n",
       " 0.16483546746174724,\n",
       " 0.1710924369747899,\n",
       " 0.16729735382704175,\n",
       " 0.16567571789337185)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score1, avg_acc1, avg_precsion1, avg_recall1, avg_f11,avg_fhalf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average auc score of aggregated model is:0.915,    average auc score of non-aggregated model is:0.913\n",
      "average accuracy of aggregated model is:0.997,     average accuracy of non-aggregated model is0.998\n",
      "average precision of aggregated model is:0.165,    average precision of non-aggregated model is:0.176\n",
      "average recall of aggregated model is:0.171,       average recall of non-aggregated model is:0.153\n",
      "average F1 score of aggregated model is:0.167,     average F1 score of non-aggregated modelis:0.161\n",
      "average F0.5 score of aggregated model is:0.166,   average F0.5 score of non-aggregated model is:0.169\n"
     ]
    }
   ],
   "source": [
    "#print the results of aggregated model and non-aggregated model respectively for Logistic regression. \n",
    "print (\"average auc score of aggregated model is:%0.3f,    average auc score of non-aggregated model is:%0.3f\" % (avg_score1,0.913))\n",
    "print (\"average accuracy of aggregated model is:%0.3f,     average accuracy of non-aggregated model is%0.3f\" % (avg_acc1,0.998))\n",
    "print (\"average precision of aggregated model is:%0.3f,    average precision of non-aggregated model is:%0.3f\" % (avg_precsion1,0.176))\n",
    "print (\"average recall of aggregated model is:%0.3f,       average recall of non-aggregated model is:%0.3f\" % (avg_recall1,0.153))\n",
    "print (\"average F1 score of aggregated model is:%0.3f,     average F1 score of non-aggregated modelis:%0.3f\" % (avg_f11,0.161))\n",
    "print (\"average F0.5 score of aggregated model is:%0.3f,   average F0.5 score of non-aggregated model is:%0.3f\" % (avg_fhalf1,0.169))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The comparison above shows that there is no significant difference between aggregated data and previous original data.\n",
    "For logistic model, some of the metrics are slightly better than previous model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
